# Critical Framework Gaps - Urgent Fixes Needed

## Date: 2024-07-27
## Severity: CRITICAL - Affects every project

## üö® Two Critical Issues Confirmed Across Multiple Phases

### 1. Decision Logging Never Happens
**Affected Phases**: PRD, Architecture (likely all phases)

**Pattern**:
- Decision log files are created with template
- AI makes decisions interactively with human
- Decisions are NEVER written to the log
- Files remain with "TBD" entries only

**Impact**:
- No audit trail of choices made
- Future phases can't reference decisions
- Defeats purpose of interactive approach

### 2. Phase Completion Never Updates project.json
**Affected Phases**: PRD, Architecture (likely all phases)

**Pattern**:
- AI creates all deliverables correctly
- Shows "‚úÖ Phase Complete!" message
- Never updates project.json status
- Next phase is blocked

**Impact**:
- Manual intervention required EVERY phase
- Breaks workflow automation
- Frustrating user experience

## üéØ Root Cause Analysis

The AI treats certain tasks as "not my job":
- **Content Creation**: ‚úÖ AI excels at this
- **Interactive Flow**: ‚úÖ AI handles well
- **Meta Tasks**: ‚ùå AI ignores completely
  - Updating configuration files
  - Logging decisions
  - Status tracking

## üîß Immediate Fixes Required

### Fix 1: Explicit Decision Logging Instructions

Update ALL phase instructions to include:
```markdown
### üìù MANDATORY: Log Every Decision

After EACH choice the human makes:
1. IMMEDIATELY update the decision log
2. Use this Python code:
   ```python
   # After user chooses frontend framework
   decision = {
       "id": "ADR-001",
       "title": "Frontend Framework Selection",
       "status": "Accepted",
       "decision": "Next.js 14",
       "alternatives": ["Vite+React", "Astro"],
       "rationale": "Full-stack capabilities needed"
   }
   # Write to architecture-decisions.md
   ```
3. Do this BEFORE moving to next decision
```

### Fix 2: Phase Completion Checklist

Add to ALL phase instructions:
```markdown
### ‚úÖ MANDATORY: Phase Completion Steps

When phase is complete:
1. Create phase-completion.md
2. RUN THIS CODE to update project.json:
   ```python
   import json
   from datetime import datetime
   
   with open('project.json', 'r+') as f:
       data = json.load(f)
       data['phases']['architecture']['status'] = 'completed'
       data['phases']['architecture']['completed'] = datetime.utcnow().isoformat() + 'Z'
       data['phases']['architecture']['artifacts'] = [
           # List all files created
       ]
       f.seek(0)
       json.dump(data, f, indent=2)
       f.truncate()
   ```
3. THEN show completion message
4. OR tell user to run: complete-phase.py architecture
```

### Fix 3: Create AI-Friendly Tools

Consider creating MCP tools for:
- `log_decision(phase, decision_data)`
- `complete_phase(phase_name, artifacts)`

This would make it natural for AI to perform these tasks.

## üìä Testing Results Summary

| Phase | Content Quality | Interactive Flow | Decision Logging | Phase Completion |
|-------|----------------|------------------|------------------|------------------|
| PRD | ‚úÖ Excellent | ‚úÖ Works well | ‚ùå Failed | ‚ùå Failed |
| Architecture | ‚úÖ Excellent | ‚úÖ Works well | ‚ùå Failed | ‚ùå Failed |

## üöÄ Action Plan

1. **Immediate**: Update all phase instruction files
2. **Short-term**: Add explicit code examples for updates
3. **Long-term**: Create tools/functions for these tasks

## üí° Key Insight

**The AI needs explicit, code-level instructions for meta tasks.**

Simply saying "update the decision log" isn't enough. We need:
- Exact code to run
- When to run it
- Validation that it happened

This is a fundamental gap in how we're instructing the AI for framework tasks vs content creation tasks.

---

*These fixes are critical for the framework to be usable. Every user will hit these issues.*